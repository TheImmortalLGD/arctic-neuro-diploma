import streamlit as st
import xarray as xr
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import load_model
import copy
import os
import time
import re
from datetime import datetime, timedelta

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
st.set_page_config(page_title="Ice Forecast NSR", layout="wide", page_icon="üö¢")
st.markdown("""
    <style>
    .stApp {background-color: #0e1117; color: white;}
    .stMetric {background-color: #1e212b; padding: 10px; border-radius: 5px; border: 1px solid #333;}
    </style>
    """, unsafe_allow_html=True)

st.title("üö¢ –ú–æ–¥–µ–ª—å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –ª–µ–¥–æ–≤–æ–π –æ–±—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞ –°–ú–ü")
st.markdown("**–°–∏—Å—Ç–µ–º–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π (–°–ü–ü–†)**")
st.markdown("---")

# --- –ú–û–î–ï–õ–¨ ---
@st.cache_resource
def load_ai_model():
    if not os.path.exists('ice_model_month_v2.h5'): return None
    return load_model('ice_model_month_v2.h5')

try:
    model = load_ai_model()
except Exception as e:
    st.error(f"–û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏: {e}")
    model = None

# --- –£–¢–ò–õ–ò–¢–´ ---
def extract_date(filename):
    match = re.search(r'(\d{8})', filename)
    if match:
        try:
            return datetime.strptime(match.group(1), "%Y%m%d")
        except:
            return None
    return None

def clean_data_initial(d):
    """–û—á–∏—Å—Ç–∫–∞ –¢–û–õ–¨–ö–û –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —Å—ã—Ä–æ–≥–æ –∫–∞–¥—Ä–∞"""
    d = np.nan_to_num(d, nan=0.0)
    d = np.where(d > 100, 0, d)
    if np.max(d) > 1.05: d = d / 100.0 # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è 0..1
    return d

# --- –ë–û–ö–û–í–ê–Ø –ü–ê–ù–ï–õ–¨ ---
with st.sidebar:
    st.header("üóÇÔ∏è –î–∞–Ω–Ω—ã–µ")
    
    if model is None:
        st.error("‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")
        st.stop()
    else:
        st.success("‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞")

    uploaded_files = st.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã (–ê–ø—Ä–µ–ª—å)", 
        type=['nc'], 
        accept_multiple_files=True
    )
    
    file_db = {}
    if uploaded_files:
        for f in uploaded_files:
            dt = extract_date(f.name)
            if dt:
                file_db[dt] = f
        
        sorted_dates = sorted(file_db.keys())
        st.info(f"–°–Ω–∏–º–∫–æ–≤: {len(file_db)}")
        
        if len(file_db) > 0:
            st.markdown("---")
            start_date = st.selectbox("–î–∞—Ç–∞ —Å—Ç–∞—Ä—Ç–∞", options=sorted_dates, format_func=lambda x: x.strftime("%d.%m.%Y"))
            horizon = st.slider("–ì–æ—Ä–∏–∑–æ–Ω—Ç (—Å—É—Ç.)", 1, 7, 3)
            
            target_date = start_date + timedelta(days=horizon)
            has_truth = target_date in file_db
            
            st.write(f"–¶–µ–ª—å: **{target_date.strftime('%d.%m.%Y')}**")
            
            if not has_truth:
                st.warning("–ù–µ—Ç —Ñ–∞–π–ª–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
                btn = False
            else:
                btn = st.button("üöÄ –í–´–ü–û–õ–ù–ò–¢–¨ –†–ê–°–ß–ï–¢", type="primary")

# --- –õ–û–ì–ò–ö–ê ---
if 'btn' in locals() and btn:
    try:
        status = st.status("–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∏ —á—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...", expanded=True)
        
        # === –§–£–ù–ö–¶–ò–Ø –ß–¢–ï–ù–ò–Ø –° –í–´–í–û–î–û–ú –û–®–ò–ë–û–ö ===
        def safe_read_debug(file_obj, temp_name):
            # 1. –ó–∞–ø–∏—Å—å
            file_obj.seek(0)
            with open(temp_name, "wb") as f:
                f.write(file_obj.read())
            
            # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ (–°—Ä–∞–∑—É —Å–∫–∞–∂–µ—Ç, –µ—Å–ª–∏ —ç—Ç–æ LFS —Å—Å—ã–ª–∫–∞)
            size = os.path.getsize(temp_name)
            if size < 3000:
                st.error(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –§–∞–π–ª '{file_obj.name}' –≤–µ—Å–∏—Ç –≤—Å–µ–≥–æ {size} –±–∞–π—Ç!")
                st.warning("–≠—Ç–æ –Ω–µ —Å–ø—É—Ç–Ω–∏–∫–æ–≤—ã–π —Å–Ω–∏–º–æ–∫, –∞ —Ç–µ–∫—Å—Ç–æ–≤–∞—è —Å—Å—ã–ª–∫–∞ GitHub LFS. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ô —Ñ–∞–π–ª —Å –≤–∞—à–µ–≥–æ –∫–æ–º–ø—å—é—Ç–µ—Ä–∞.")
                st.stop()

            # 3. –ü–æ–ø—ã—Ç–∫–∞ –æ—Ç–∫—Ä—ã—Ç—å —Ä–∞–∑–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏
            engines = ['netcdf4', 'h5netcdf', 'scipy']
            errors_log = []
            
            for eng in engines:
                try:
                    ds = xr.open_dataset(temp_name, engine=eng)
                    # –ï—Å–ª–∏ –æ—Ç–∫—Ä—ã–ª–æ—Å—å - —É—Ä–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º
                    return ds
                except Exception as e:
                    errors_log.append(f"–î–≤–∏–∂–æ–∫ '{eng}': {str(e)}")
            
            # –ï—Å–ª–∏ –¥–æ—à–ª–∏ —Å—é–¥–∞ - –∑–Ω–∞—á–∏—Ç –Ω–∏ –æ–¥–∏–Ω –Ω–µ –æ—Ç–∫—Ä—ã–ª
            st.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª '{file_obj.name}'. –û—Ç—á–µ—Ç –æ–± –æ—à–∏–±–∫–∞—Ö:")
            for err in errors_log:
                st.code(err, language='text')
            
            st.info("üí° –ü–û–î–°–ö–ê–ó–ö–ê: –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ 'HDF error' - —Ñ–∞–π–ª –±–∏—Ç—ã–π. –ï—Å–ª–∏ 'libnetcdf not found' - –Ω–µ—Ç packages.txt.")
            st.stop()

        # 1. –ß–¢–ï–ù–ò–ï –°–¢–ê–†–¢–ê
        ds = safe_read_debug(file_db[start_date], "temp_start.nc")
        var_name = [v for v in ds.data_vars if 'ice' in v or 'conc' in v][0]
        data_raw = ds[var_name].isel(time=0).squeeze().values
        
        # –ú–∞—Å–∫–∞
        land_mask = np.isnan(data_raw) | (data_raw > 100)
        orig_shape = data_raw.shape
        
        # –ü–µ—Ä–≤–∏—á–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
        current_img = clean_data_initial(data_raw)
        
        # –¢–µ–Ω–∑–æ—Ä
        input_tensor = tf.image.resize(current_img[..., np.newaxis], [256, 256])
        input_batch = np.expand_dims(input_tensor, axis=0)
        
        # 2. –¶–ò–ö–õ –ü–†–û–ì–ù–û–ó–ê
        prog_bar = status.progress(0)
        alpha = 0.75 
        
        for day in range(1, horizon + 1):
            pred_ai = model.predict(input_batch, verbose=0)
            pred_stab = (input_batch * alpha) + (pred_ai * (1 - alpha))
            pred_clean = tf.where(pred_stab > 0.1, pred_stab, 0.0)
            input_batch = pred_clean
            
            status.write(f"‚úÖ –î–µ–Ω—å {day}: –†–∞—Å—á–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω")
            prog_bar.progress(day / horizon)
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç
        final_full = tf.image.resize(input_batch[0], [orig_shape[0], orig_shape[1]]).numpy().squeeze()
        final_viz = copy.deepcopy(final_full)
        final_viz[land_mask] = np.nan
        
        status.update(label="–ì–æ—Ç–æ–≤–æ", state="complete", expanded=False)

        # 3. –§–ê–ö–¢
        ds_t = safe_read_debug(file_db[target_date], "temp_target.nc")
        target_raw = ds_t[var_name].isel(time=0).squeeze().values
        target_clean = clean_data_initial(target_raw)
        
        target_viz = copy.deepcopy(target_clean)
        target_viz[land_mask] = np.nan
        
        # 4. –ú–ï–¢–†–ò–ö–ò
        diff_map = np.abs(final_full - target_clean)
        diff_map[land_mask] = np.nan
        
        mae = np.nanmean(diff_map) * 100
        accuracy = 100 - mae

        # 5. –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø
        st.subheader(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç (–ì–æ—Ä–∏–∑–æ–Ω—Ç: {horizon} —Å—É—Ç.)")
        
        c1, c2, c3 = st.columns(3)
        cmap = plt.cm.Blues_r.copy()
        cmap.set_bad('#1E1E1E')
        
        with c1:
            st.markdown("### üß† –ü—Ä–æ–≥–Ω–æ–∑ –ò–ò")
            fig1, ax1 = plt.subplots(figsize=(6,6), facecolor='#0e1117')
            ax1.imshow(final_viz, cmap=cmap, vmin=0, vmax=1)
            ax1.axis('off')
            st.pyplot(fig1)
            
        with c2:
            st.markdown("### üõ∞Ô∏è –§–∞–∫—Ç")
            fig2, ax2 = plt.subplots(figsize=(6,6), facecolor='#0e1117')
            ax2.imshow(target_viz, cmap=cmap, vmin=0, vmax=1)
            ax2.axis('off')
            st.pyplot(fig2)
            
        with c3:
            st.markdown("### üî• –û—à–∏–±–∫–∏")
            fig3, ax3 = plt.subplots(figsize=(6,6), facecolor='#0e1117')
            im = ax3.imshow(diff_map, cmap='hot', vmin=0, vmax=0.5)
            ax3.axis('off')
            st.pyplot(fig3)
            
        st.markdown("---")
        m1, m2, m3 = st.columns(3)
        m1.metric("–¢–æ—á–Ω–æ—Å—Ç—å", f"{accuracy:.2f}%")
        m2.metric("MAE", f"{mae:.2f}%")
        m3.metric("–°—Ç–∞—Ç—É—Å", "‚úÖ –ù–û–†–ú–ê" if accuracy > 80 else "‚ö†Ô∏è")

    except Exception as e:
        st.error(f"–°–∏—Å—Ç–µ–º–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")

elif not uploaded_files:
    st.info("üëà –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã.")
