import streamlit as st
import xarray as xr
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import load_model
import copy
import h5netcdf
import os
import time
import re
import glob
from datetime import datetime, timedelta

# --- –ù–ê–°–¢–†–û–ô–ö–ò –ò–ù–¢–ï–†–§–ï–ô–°–ê ---
st.set_page_config(page_title="Ice Forecast NSR", layout="wide", page_icon="üö¢")
st.markdown("""
    <style>
    .stApp {background-color: #0e1117; color: white;}
    .stMetric {background-color: #1e212b; padding: 10px; border-radius: 5px; border: 1px solid #333;}
    .css-10trblm {font-size: 1.2rem; font-weight: bold;}
    </style>
    """, unsafe_allow_html=True)

st.title("üö¢ –ú–æ–¥–µ–ª—å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –ª–µ–¥–æ–≤–æ–π –æ–±—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞ –°–ú–ü")
st.markdown("**–ú–æ–¥—É–ª—å –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏–≤–∞ –¥–∞–Ω–Ω—ã—Ö**")
st.markdown("---")

# --- –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ò ---
@st.cache_resource
def load_ai_model():
    if not os.path.exists('ice_model_month_v2.h5'): return None
    return load_model('ice_model_month_v2.h5')

try:
    model = load_ai_model()
except Exception as e:
    st.error(f"–û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏: {e}")
    model = None

# --- –ü–ê–†–°–ò–ù–ì –î–ê–¢ ---
def extract_date(filename):
    match = re.search(r'(\d{8})', filename)
    if match:
        try:
            return datetime.strptime(match.group(1), "%Y%m%d")
        except:
            return None
    return None

# --- –§–£–ù–ö–¶–ò–Ø –ß–¢–ï–ù–ò–Ø (–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è) ---
def read_nc_file(file_obj):
    """–ß–∏—Ç–∞–µ—Ç —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –±–∞–π—Ç—ã, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Ç–æ–≥–æ, –∑–∞–≥—Ä—É–∂–µ–Ω –æ–Ω –∏–ª–∏ –ª–µ–∂–∏—Ç –ª–æ–∫–∞–ª—å–Ω–æ"""
    if isinstance(file_obj, str): # –ï—Å–ª–∏ —ç—Ç–æ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É (–Ω–∞ GitHub)
        with open(file_obj, "rb") as f:
            return f.read()
    else: # –ï—Å–ª–∏ —ç—Ç–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª (UploadedFile)
        file_obj.seek(0)
        return file_obj.read()

# --- –ë–û–ö–û–í–ê–Ø –ü–ê–ù–ï–õ–¨ ---
with st.sidebar:
    st.header("üóÇÔ∏è –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
    
    if model is None:
        st.error("‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        st.stop()
    else:
        st.success("‚úÖ –ù–µ–π—Ä–æ—Å–µ—Ç—å –∞–∫—Ç–∏–≤–Ω–∞")
    
    # 1. –ê–í–¢–û-–ü–û–ò–°–ö –§–ê–ô–õ–û–í –í –†–ï–ü–û–ó–ò–¢–û–†–ò–ò
    local_files = glob.glob("*.nc") # –ò—â–µ–º –≤—Å–µ .nc —Ñ–∞–π–ª—ã —Ä—è–¥–æ–º —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º
    # –ò—Å–∫–ª—é—á–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –º—ã —Å–∞–º–∏ —Å–æ–∑–¥–∞–µ–º
    local_files = [f for f in local_files if "temp" not in f]
    
    file_db = {}
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã (—Å GitHub)
    for f_path in local_files:
        dt = extract_date(f_path)
        if dt:
            file_db[dt] = f_path # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Ç—å –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
            
    # 2. –†–£–ß–ù–ê–Ø –ó–ê–ì–†–£–ó–ö–ê (–ï—Å–ª–∏ –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —á—Ç–æ-—Ç–æ –µ—â–µ)
    uploaded_files = st.file_uploader(
        "–î–æ–±–∞–≤–∏—Ç—å —Ñ–∞–π–ª—ã –≤—Ä—É—á–Ω—É—é (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)", 
        type=['nc'], 
        accept_multiple_files=True
    )
    
    if uploaded_files:
        for f in uploaded_files:
            dt = extract_date(f.name)
            if dt:
                file_db[dt] = f # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–∫—Ç —Ñ–∞–π–ª–∞
    
    # –ò–¢–û–ì–û–í–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø
    sorted_dates = sorted(file_db.keys())
    count_local = len([x for x in file_db.values() if isinstance(x, str)])
    count_upload = len(file_db) - count_local
    
    st.caption(f"üìö –í –±–∞–∑–µ: {len(file_db)} —Å–Ω–∏–º–∫–æ–≤")
    if count_local > 0:
        st.caption(f"‚Ä¢ –ò–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è: {count_local}")
    if count_upload > 0:
        st.caption(f"‚Ä¢ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –≤—Ä—É—á–Ω—É—é: {count_upload}")

    if len(file_db) > 0:
        st.markdown("---")
        
        # –í–´–ë–û–† –î–ê–¢–´ –°–¢–ê–†–¢–ê
        start_date = st.selectbox(
            "1. –î–∞—Ç–∞ —Å—Ç–∞—Ä—Ç–∞", 
            options=sorted_dates,
            format_func=lambda x: x.strftime("%d.%m.%Y")
        )
        
        # –í–´–ë–û–† –ì–û–†–ò–ó–û–ù–¢–ê
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º, —á—Ç–æ–±—ã –Ω–µ –≤—ã–π—Ç–∏ –∑–∞ –ø—Ä–µ–¥–µ–ª—ã –∏–º–µ—é—â–∏—Ö—Å—è —Ñ–∞–π–ª–æ–≤
        horizon = st.slider("2. –ì–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞ (—Å—É—Ç–æ–∫)", 1, 7, 3)
        
        # –¶–ï–õ–ï–í–ê–Ø –î–ê–¢–ê
        target_date = start_date + timedelta(days=horizon)
        has_truth = target_date in file_db
        
        st.info(f"üìÖ –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞: **{target_date.strftime('%d.%m.%Y')}**")
        
        if has_truth:
            st.caption("‚úÖ –î–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –µ—Å—Ç—å")
            btn_disabled = False
        else:
            st.warning(f"‚ö†Ô∏è –ù–µ—Ç —Ñ–∞–π–ª–∞ –∑–∞ {target_date.strftime('%d.%m')}")
            btn_disabled = True
        
        predict_btn = st.button("üöÄ –ó–ê–ü–£–°–¢–ò–¢–¨", type="primary", disabled=btn_disabled)

# --- –û–°–ù–û–í–ù–ê–Ø –õ–û–ì–ò–ö–ê ---
if 'predict_btn' in locals() and predict_btn:
    try:
        status_container = st.status("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —è–¥—Ä–∞ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è...", expanded=True)
        
        # 1. –ß–¢–ï–ù–ò–ï –°–¢–ê–†–¢–ê
        file_content = read_nc_file(file_db[start_date])
        with open("start_temp.nc", "wb") as f: f.write(file_content)
        
        ds = xr.open_dataset("start_temp.nc", engine='h5netcdf')
        var_name = [v for v in ds.data_vars if 'ice' in v or 'conc' in v][0]
        data_raw = ds[var_name].isel(time=0).squeeze().values
        
        land_mask = np.isnan(data_raw) | (data_raw > 100)
        orig_shape = data_raw.shape
        
        def clean(d):
            d = np.nan_to_num(d, nan=0.0)
            d = np.where(d > 100, 0, d)
            if np.max(d) > 1.05: d = d / 100.0
            return d

        current_img = clean(data_raw)
        
        input_tensor = tf.image.resize(current_img[..., np.newaxis], [256, 256])
        input_batch = np.expand_dims(input_tensor, axis=0)
        
        # 2. –¶–ò–ö–õ –ü–†–û–ì–ù–û–ó–ê (–° –ò–ù–ï–†–¶–ò–ï–ô)
        progress_bar = status_container.progress(0)
        alpha = 0.75 
        
        for day in range(1, horizon + 1):
            pred_ai = model.predict(input_batch, verbose=0)
            pred_stabilized = (input_batch * alpha) + (pred_ai * (1 - alpha))
            pred_clean = tf.where(pred_stabilized > 0.1, pred_stabilized, 0.0)
            input_batch = pred_clean 
            
            sim_date = start_date + timedelta(days=day)
            status_container.write(f"‚úÖ –†–∞—Å—á–µ—Ç: {sim_date.strftime('%d.%m.%Y')}")
            progress_bar.progress(day / horizon)
            time.sleep(0.05)
            
        # 3. –ü–û–°–¢-–û–ë–†–ê–ë–û–¢–ö–ê
        final_small = input_batch[0]
        final_full = tf.image.resize(final_small, [orig_shape[0], orig_shape[1]]).numpy().squeeze()
        
        final_viz = copy.deepcopy(final_full)
        final_viz[land_mask] = np.nan
        
        status_container.update(label="–ú–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ", state="complete", expanded=False)

        # 4. –ü–û–î–ì–û–¢–û–í–ö–ê –§–ê–ö–¢–ê
        target_content = read_nc_file(file_db[target_date])
        with open("target_temp.nc", "wb") as f: f.write(target_content)
        
        ds_target = xr.open_dataset("target_temp.nc", engine='h5netcdf')
        target_raw = ds_target[var_name].isel(time=0).squeeze().values
        target_clean = clean(target_raw)
        
        target_viz = copy.deepcopy(target_clean)
        target_viz[land_mask] = np.nan
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        diff = np.abs(final_full - target_clean)
        diff[land_mask] = np.nan
        mae = np.nanmean(diff) * 100
        accuracy = 100 - mae

        # 5. –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø
        st.subheader(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ {horizon} —Å—É—Ç.")
        
        col1, col2 = st.columns(2)
        cmap = plt.cm.Blues_r.copy()
        cmap.set_bad('#1E1E1E')
        
        with col1:
            st.markdown(f"### üß† –ü—Ä–æ–≥–Ω–æ–∑ –ò–ò")
            st.caption(f"–î–∞—Ç–∞: {target_date.strftime('%d.%m.%Y')}")
            fig1, ax1 = plt.subplots(figsize=(8, 8), facecolor='#0e1117')
            ax1.imshow(final_viz, cmap=cmap, vmin=0, vmax=1)
            ax1.axis('off')
            st.pyplot(fig1)
            
        with col2:
            st.markdown(f"### üõ∞Ô∏è –§–∞–∫—Ç (–°–ø—É—Ç–Ω–∏–∫)")
            st.caption(f"–î–∞—Ç–∞: {target_date.strftime('%d.%m.%Y')}")
            fig2, ax2 = plt.subplots(figsize=(8, 8), facecolor='#0e1117')
            ax2.imshow(target_viz, cmap=cmap, vmin=0, vmax=1)
            ax2.axis('off')
            st.pyplot(fig2)
        
        st.markdown("---")
        m1, m2, m3 = st.columns(3)
        m1.metric("–¢–æ—á–Ω–æ—Å—Ç—å (Accuracy)", f"{accuracy:.2f}%")
        m2.metric("MAE", f"{mae:.2f}%")
        m3.metric("–†–µ–∑—É–ª—å—Ç–∞—Ç", "–£–°–ü–ï–•" if accuracy > 75 else "–ù–ò–ñ–ï –ù–û–†–ú–´", delta="OK" if accuracy > 75 else "Warn")
        
        with st.expander("üîé –ö–∞—Ä—Ç–∞ –æ—à–∏–±–æ–∫"):
            fig_err, ax_err = plt.subplots(figsize=(10, 4), facecolor='#0e1117')
            diff_viz = copy.deepcopy(diff)
            im = ax_err.imshow(diff_viz, cmap='hot', vmin=0, vmax=0.5)
            plt.colorbar(im, ax=ax_err, label="–û—à–∏–±–∫–∞")
            ax_err.axis('off')
            st.pyplot(fig_err)

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {e}")

elif len(file_db) == 0:
    st.info("–í —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –Ω–µ—Ç —Ñ–∞–π–ª–æ–≤ .nc. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏—Ö –Ω–∞ GitHub –∏–ª–∏ –ø–µ—Ä–µ—Ç–∞—â–∏—Ç–µ —Å—é–¥–∞ –≤—Ä—É—á–Ω—É—é.")
