import streamlit as st
import xarray as xr
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import load_model
import copy
import os
import time
import re
from datetime import datetime, timedelta

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
st.set_page_config(page_title="Ice Forecast NSR", layout="wide", page_icon="üö¢")
st.markdown("""
    <style>
    .stApp {background-color: #0e1117; color: white;}
    .stMetric {background-color: #1e212b; padding: 10px; border-radius: 5px; border: 1px solid #333;}
    </style>
    """, unsafe_allow_html=True)

st.title("üö¢ –ú–æ–¥–µ–ª—å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –ª–µ–¥–æ–≤–æ–π –æ–±—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞ –°–ú–ü")
st.markdown("**–°–∏—Å—Ç–µ–º–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π (–°–ü–ü–†)**")
st.markdown("---")

# --- –ú–û–î–ï–õ–¨ ---
@st.cache_resource
def load_ai_model():
    if not os.path.exists('ice_model_month_v2.h5'): return None
    return load_model('ice_model_month_v2.h5')

try:
    model = load_ai_model()
except Exception as e:
    st.error(f"–û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏: {e}")
    model = None

# --- –£–¢–ò–õ–ò–¢–´ ---
def extract_date(filename):
    match = re.search(r'(\d{8})', filename)
    if match:
        try:
            return datetime.strptime(match.group(1), "%Y%m%d")
        except:
            return None
    return None

def clean_data_initial(d):
    """–û—á–∏—Å—Ç–∫–∞ –¢–û–õ–¨–ö–û –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —Å—ã—Ä–æ–≥–æ –∫–∞–¥—Ä–∞"""
    d = np.nan_to_num(d, nan=0.0)
    d = np.where(d > 100, 0, d)
    if np.max(d) > 1.05: d = d / 100.0 # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è 0..1
    return d

# --- –ë–û–ö–û–í–ê–Ø –ü–ê–ù–ï–õ–¨ ---
with st.sidebar:
    st.header("üóÇÔ∏è –î–∞–Ω–Ω—ã–µ")
    
    if model is None:
        st.error("‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")
        st.stop()
    else:
        st.success("‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞")

    uploaded_files = st.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã (–ê–ø—Ä–µ–ª—å)", 
        type=['nc'], 
        accept_multiple_files=True
    )
    
    file_db = {}
    if uploaded_files:
        for f in uploaded_files:
            dt = extract_date(f.name)
            if dt:
                file_db[dt] = f
        
        sorted_dates = sorted(file_db.keys())
        st.info(f"–°–Ω–∏–º–∫–æ–≤: {len(file_db)}")
        
        if len(file_db) > 0:
            st.markdown("---")
            start_date = st.selectbox("–î–∞—Ç–∞ —Å—Ç–∞—Ä—Ç–∞", options=sorted_dates, format_func=lambda x: x.strftime("%d.%m.%Y"))
            horizon = st.slider("–ì–æ—Ä–∏–∑–æ–Ω—Ç (—Å—É—Ç.)", 1, 7, 3)
            
            target_date = start_date + timedelta(days=horizon)
            has_truth = target_date in file_db
            
            st.write(f"–¶–µ–ª—å: **{target_date.strftime('%d.%m.%Y')}**")
            
            if not has_truth:
                st.warning("–ù–µ—Ç —Ñ–∞–π–ª–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
                btn = False
            else:
                btn = st.button("üöÄ –í–´–ü–û–õ–ù–ò–¢–¨ –†–ê–°–ß–ï–¢", type="primary")

# --- –õ–û–ì–ò–ö–ê ---
if 'btn' in locals() and btn:
    try:
        status = st.status("–†–∞—Å—á–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞...", expanded=True)
        
        # === –§–£–ù–ö–¶–ò–Ø –ë–ï–ó–û–ü–ê–°–ù–û–ì–û –ß–¢–ï–ù–ò–Ø ===
        def safe_read(file_obj, temp_name):
            file_obj.seek(0)
            with open(temp_name, "wb") as f:
                f.write(file_obj.read())
            
            engines = ['netcdf4', 'h5netcdf', 'scipy', None]
            for eng in engines:
                try:
                    return xr.open_dataset(temp_name, engine=eng)
                except:
                    continue
            raise ValueError("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞")

        # 1. –ß–¢–ï–ù–ò–ï –°–¢–ê–†–¢–ê
        ds = safe_read(file_db[start_date], "temp_start.nc")
        var_name = [v for v in ds.data_vars if 'ice' in v or 'conc' in v][0]
        data_raw = ds[var_name].isel(time=0).squeeze().values
        
        # –ú–∞—Å–∫–∞ —Å—É—à–∏ (–∑–∞–ø–æ–º–∏–Ω–∞–µ–º –æ–¥–∏–Ω —Ä–∞–∑)
        land_mask = np.isnan(data_raw) | (data_raw > 100)
        orig_shape = data_raw.shape
        
        # –ü–µ—Ä–≤–∏—á–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
        current_img = clean_data_initial(data_raw)
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–Ω–∑–æ—Ä–∞
        input_tensor = tf.image.resize(current_img[..., np.newaxis], [256, 256])
        input_batch = np.expand_dims(input_tensor, axis=0)
        
        # 2. –¶–ò–ö–õ –ü–†–û–ì–ù–û–ó–ê (–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô)
        prog_bar = status.progress(0)
        alpha = 0.75 
        
        for day in range(1, horizon + 1):
            # –ü—Ä–æ–≥–Ω–æ–∑
            pred_ai = model.predict(input_batch, verbose=0)
            
            # –°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è
            pred_stab = (input_batch * alpha) + (pred_ai * (1 - alpha))
            pred_clean = tf.where(pred_stab > 0.1, pred_stab, 0.0)
            
            # –í–ê–ñ–ù–û: –ú—ã –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–¥–∞–µ–º –≤—ã—Ö–æ–¥ –Ω–∞ –≤—Ö–æ–¥ —Å–ª–µ–¥—É—é—â–µ–≥–æ —à–∞–≥–∞
            # –ë–µ–∑ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏!
            input_batch = pred_clean
            
            status.write(f"‚úÖ –î–µ–Ω—å {day}: –ì–æ—Ç–æ–≤–æ")
            prog_bar.progress(day / horizon)
        
        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞
        final_full = tf.image.resize(input_batch[0], [orig_shape[0], orig_shape[1]]).numpy().squeeze()
        final_viz = copy.deepcopy(final_full)
        final_viz[land_mask] = np.nan
        
        status.update(label="–£—Å–ø–µ—à–Ω–æ", state="complete", expanded=False)

        # 3. –§–ê–ö–¢
        ds_t = safe_read(file_db[target_date], "temp_target.nc")
        target_raw = ds_t[var_name].isel(time=0).squeeze().values
        
        # –§–∞–∫—Ç –Ω—É–∂–Ω–æ –æ—á–∏—Å—Ç–∏—Ç—å —Ç–æ–π –∂–µ —Ñ—É–Ω–∫—Ü–∏–µ–π, —á—Ç–æ –∏ —Å—Ç–∞—Ä—Ç
        target_clean = clean_data_initial(target_raw)
        target_viz = copy.deepcopy(target_clean)
        target_viz[land_mask] = np.nan
        
        # 4. –ú–ï–¢–†–ò–ö–ò
        diff_map = np.abs(final_full - target_clean)
        diff_map[land_mask] = np.nan
        
        mae = np.nanmean(diff_map) * 100
        accuracy = 100 - mae

        # 5. –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø
        st.subheader(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç (–ì–æ—Ä–∏–∑–æ–Ω—Ç: {horizon} —Å—É—Ç.)")
        
        c1, c2, c3 = st.columns(3)
        cmap = plt.cm.Blues_r.copy()
        cmap.set_bad('#1E1E1E')
        
        with c1:
            st.markdown("### üß† –ü—Ä–æ–≥–Ω–æ–∑ –ò–ò")
            fig1, ax1 = plt.subplots(figsize=(6,6), facecolor='#0e1117')
            ax1.imshow(final_viz, cmap=cmap, vmin=0, vmax=1)
            ax1.axis('off')
            st.pyplot(fig1)
            
        with c2:
            st.markdown("### üõ∞Ô∏è –§–∞–∫—Ç")
            fig2, ax2 = plt.subplots(figsize=(6,6), facecolor='#0e1117')
            ax2.imshow(target_viz, cmap=cmap, vmin=0, vmax=1)
            ax2.axis('off')
            st.pyplot(fig2)
            
        with c3:
            st.markdown("### üî• –û—à–∏–±–∫–∏")
            fig3, ax3 = plt.subplots(figsize=(6,6), facecolor='#0e1117')
            im = ax3.imshow(diff_map, cmap='hot', vmin=0, vmax=0.5)
            ax3.axis('off')
            st.pyplot(fig3)
            
        st.markdown("---")
        m1, m2, m3 = st.columns(3)
        m1.metric("–¢–æ—á–Ω–æ—Å—Ç—å", f"{accuracy:.2f}%")
        m2.metric("MAE", f"{mae:.2f}%")
        m3.metric("–°—Ç–∞—Ç—É—Å", "‚úÖ –ù–û–†–ú–ê" if accuracy > 80 else "‚ö†Ô∏è")

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞: {e}")

elif not uploaded_files:
    st.info("üëà –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã.")
